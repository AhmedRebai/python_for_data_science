{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Régression linéaire avec Python\n",
    "\n",
    "\n",
    "## Modélisation des données\n",
    "\n",
    "### Introduction \n",
    "\n",
    "Étant donné un ensemble d'observations (des données \"data\"), on veut souvent condenser et résumer les données en l'adaptant à un modèle qui dépend de paramètres ajustables. Parfois, le modèle est simplement une fonction usuelle (un polynôme, une gaussienne...), et l'ajustement fournit les coefficients appropriés.\n",
    "\n",
    "\n",
    "Une approche très générale a le paradigme suivant: on choisit ou on conçoit une fonction objectif (une fonction coût, une fonction de mérite) qui mesure l'accord entre les données et le modèle avec un choix particulier de paramètres. \n",
    "\n",
    "\n",
    "En statistiques fréquentistes, la fonction objectif est classiquement organisée de telle sorte que les petites valeurs représentent un accord étroit avec les données. Les bayésiens choisissent comme fonction objectif la probabilité des paramètres sachant les données (ou souvent leur logarithme), de sorte que des grandes valeurs de cette probabilité représentent un accord plus étroit avec les données.\n",
    "\n",
    "\n",
    "- Dans les deux approches, les paramètres du modèle sont ensuite ajustés pour trouver un le meilleur extremum dans la fonction objectif, produisant les paramètres les mieux adaptés. Ainsi, le processus d'ajustement se formule sous la forme d'un problème d'optimisation (minimisation ou maximisation) en plusieurs dimensions.\n",
    "\n",
    "\n",
    "Notons bien que la détermination des meilleurs paramètres ne marque pas la fin du processus d'ajustement car il y a des questions importantes qui vont au-delà de cette détermination. Les données ne sont généralement pas exactes, elles sont sujets à des erreurs de mesure (appelées bruit comme dans le contexte du traitement du signal). Ainsi, les données typiques ne corrspondent jamais exactement au modèle utilisé, même si ce modèle est correct. Alors nous avons besoin de moyens pour évaluer si le modèle est approprié ou non, c'est-à-dire que nous devons tester la qualité de l'ajustement avec les tests statistiques. Il est alors nécessaire de connaître la précision des paramètres déterminés à partir des données. \n",
    "\n",
    "Les fréquentistes cherchent à connaître les erreurs sur les paramètres optimaux. Les Bayésiens veulent trouver non seulement le maximum de la distribution de probabilités des paramètres mais aussi la distribution complète.\n",
    "\n",
    "\n",
    "### Approche fréquentiste ou approche bayésienne\n",
    "\n",
    "D'une manière générale, l'observation expérimentale consiste à collecter des données pour tester la validité d'une théorie ou d'une hypothèse qui se basent sur un modèle analytique dépendant de plusieurs paramètres. Pour ce faire, un estimateur est construit qui mesure l'accord entre les données et le modèle. \n",
    "\n",
    "L'approche est dénomée 'fréquentiste' si cet estimateur est construit de telle façon que son minimum global représente l'accord parfait, c'est-à-dire la solution recherchée avec une certaine erreur. Elle est nommée 'bayésienne' si l'estimateur représente une probabilité des paramètres pour lesquels son maximum global représente l'accord parfait, c'est-à-dire la solution avec une certaine probabilité. Par exemple, ces paramètres peuvent servir à extrapoler des mesures expérimentales dans un intervalle d'une grandeur statistique. \n",
    "\n",
    "\n",
    "Dans l'approche fréquentiste, la détermination d'un paramètre estimé $\\alpha$ fait appel à la probabilité $p(X|\\alpha)$ d'observer la mesure X pour une valeur de $\\alpha$ donnée. Cette probabilité correspond à la fréquence d'occurrence de la mesure X si l'on répète l'expérience un grand nombre de fois. On définit alors la fonction du maximum de vraisemblance (likelihood) comme le produit des probabilités associées à chacune des expériences: \n",
    "\n",
    "$$ L(\\alpha) = \\Pi_{i=1}^N p(X_i|\\alpha) $$ \n",
    "\n",
    "avec $p(X_i|\\alpha)$ la fonction densité de probabilité de la mesure $X_i$ pour un $\\alpha$. Quantitativement, on suppose que chaque mesure $X_i$ est affectée par une erreur aléatoire et distribuée selon une distribution gaussienne autour de la vraie valeur Y(X) avec la déviation standard $\\sigma_i$ (l'erreur de ces distributions gaussiennes). La fonction du maximum de vraisemblance s'écrit alors:\n",
    "\n",
    "$$ L(\\alpha) = \\Pi_{i=1}^N exp(-\\frac{1}{2}.(\\frac{Y_i - Y(X_i)}{\\sigma_i})^2).dY$$\n",
    "\n",
    "Finalement, le paramètre est estimé d'une manière qui assure sa valeur dans un intervalle de confiance qui représente conventionnellement 95% des cas possibles (ou d'autres valeurs comme 68%, 99.7%, etc.). Cette approche nécessite de construire des modèles paramétriques comme les distributions normales, de student ou de $\\chi^2$.\n",
    "\n",
    "\n",
    "L'approche Bayésienne considère le paramètre $\\alpha$ comme une variable aléatoire à laquelle on peut associer une fonction densité de probabilité $p(\\alpha|X)$, et que l'on peut contraindre grâce à la mesure X en utilisant le théorème de Bayes stipulant que \n",
    "\n",
    "$$ p(\\alpha| X) = \\frac{p(X|\\alpha).p(\\alpha)}{p(X)}$$ \n",
    "\n",
    "Le terme $p(\\alpha)$ est la densité de probabilité de $\\alpha$ à priori, aussi appelé 'prior'. Elle précède toute information sur X et doit être choisie arbitrairement. Dans ce cas, l'intervalle de confiance est construit suivant cette distribution. Cette approche considère l'inconnue comme un paramètre, le terme inconnu inclut par exemple l'information manquante ou les modèles non-identifiables et on s'intéresse à la vérification après l'identificationdes paramètres.\n",
    "\n",
    "\n",
    "- Dans la vie réelle, afin d'éviter l'introduction d'un prior arbitraire qui pourrait biaiser l'estimation des paramètres, on peut choisir l'approche fréquentiste.\n",
    "\n",
    "\n",
    "\n",
    "### Optimisation déterministe ou optimisation stochastique\n",
    "\n",
    "L'optimisation est une branche des mathématiques qui a pour but de trouver la meilleure solution possible d'un problème donné. Par exemple, en mécanique comme un système en mouvement tend toujours vers la position qui lui permet de consommer le moins d'énergie possible, les mécanismes cherchent toujours les meilleurs paramètres qui optimisent la performance de leurs machines. \n",
    "\n",
    "\n",
    "En finance, les investisseurs sur les marchés financiers cherchent à constituer des portefolios qui évitent les risques excessifs tout en garantissant un taux de rentablité élevé, etc. D'une manière générale le problème peut se traduire sous la forme suivante:\n",
    "\n",
    "\n",
    "$$ minimiser ~ f(x)$$\n",
    "\n",
    "$$ soumis~à~c_i(x) \\leq b_i,~i = 1,...,m$$\n",
    "\n",
    "où $x=(x_1,...,x_n)$ est un vecteur de paramètres du problème, la fonction $f:\\mathbb{R}^n \\rightarrow \\mathbb{R}$ est l'estimateur (appelée aussi fonction objectif), les fonctions $c_i:\\mathbb{R}^n \\rightarrow \\mathbb{R}, i = 1, ..., m$, sont les contraintes du problème, et les constantes $b_1, ..., b_m$ sont les limites, ou les bornes des contraintes. \n",
    "\n",
    "\n",
    "La solution du problème est le vecteur $x_s$ satisfaisant les inégalités suivantes:\n",
    "\n",
    "$$ \\forall z, c_1(z) \\leq b_1, ..., c_m(z) \\leq b_m, f(z) \\geq f(x_s) $$\n",
    "\n",
    "\n",
    "et est obtenue par la minimisation d'une fonction objectif d'une manière analytique.\n",
    "\n",
    "\n",
    "\n",
    "En optimisation déterministe, les grandeurs pertinentes sont les vecteurs des paramètres x. Par contre en optimisation stochastique, les grandeurs pertinentes sont des lois de probabilités; pour cela les algorithmes utilisent des informations a priori sur les paramètres inconnus du modèle pour produire la solution du problème. De point de vue pratique, on classe généralement la qualité des algorithmes d'optimisation en fonction de leurs propriétés, comme la robustesse (qui qualifie la capacité de l'algorithme à trouver la solution pour plusieurs classes de problèmes différents et ceci en fonction des valeurs initiales raisonnables), l'efficacité (qui qualifie les ressources nécessaires en temps d'exécution ou bien en mémoire vive), la précision (qui identifie la capacité à fournir et à identifier la solution avec précision en réduisant la sensibilité aux différentes types des erreurs).\n",
    "\n",
    "\n",
    "- Eu égard à la complexité de l'approche stochastique par rapport à celle déterministe et pour éviter l'introduction d'un prior arbitraire, le data-scientist peut choisir l'utilisation des algorithmes déterministes pendant le processus de minimisation de la fonction objectif.\n",
    "\n",
    "- Notons que c'est contre intuitif de dire que les méthodes stochastiques sont les plus efficaces pendant le processus de minimisation! Par exemple, l'algorithme du gradient stochastique.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
